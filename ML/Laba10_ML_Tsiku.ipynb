{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №10. ОСНОВЫ ОБРАБОТКИ ЕСТЕСТВЕННОГО ЯЗЫКА (NLP). ЗАДАЧА ТЕМАТИЧЕСКОГО МОДЕЛИРОВАНИЯ\n",
    "\n",
    "ЗАДАНИЕ\n",
    "1. Для выполнения задания используйте датасет с данными о спаме (https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset).\n",
    "2***. Самостоятельно реализовать BoW, TF-IDF.\n",
    "3. Решить задачу классификации с понижением размерности.\n",
    "*** Использовать самостоятельно реализованные модели из предыдущих ЛР.\n",
    "4. Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # Удаление специальных символов и приведение к нижнему регистру\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Применение функции очистки к датасету\n",
    "data['v2'] = data['v2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey there darling it s been 3 week s n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 11 months or more u r entitled...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  go until jurong point crazy available only in ...        NaN   \n",
       "1   ham                            ok lar joking wif u oni        NaN   \n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...        NaN   \n",
       "3   ham        u dun say so early hor u c already then say        NaN   \n",
       "4   ham  nah i don t think he goes to usf he lives arou...        NaN   \n",
       "5  spam  freemsg hey there darling it s been 3 week s n...        NaN   \n",
       "6   ham  even my brother is not like to speak with me t...        NaN   \n",
       "7   ham  as per your request melle melle oru minnaminun...        NaN   \n",
       "8  spam  winner as a valued network customer you have b...        NaN   \n",
       "9  spam  had your mobile 11 months or more u r entitled...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['v2'], data['v1'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Самостоятельно реализовать BoW, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(texts):\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        vocab.update(text.split())\n",
    "    return sorted(vocab)\n",
    "\n",
    "# BoW\n",
    "def bow(texts, vocabulary):\n",
    "    bow_vectors = []\n",
    "    vocab_indices = {word: i for i, word in enumerate(vocabulary)}\n",
    "    for text in texts:\n",
    "        tokenized = text.split()\n",
    "        bow_vector = np.zeros(len(vocabulary))\n",
    "        for token in tokenized:\n",
    "            if token in vocab_indices:\n",
    "                bow_vector[vocab_indices[token]] += 1\n",
    "        bow_vectors.append(bow_vector)\n",
    "    return np.array(bow_vectors)\n",
    "\n",
    "# TF-IDF\n",
    "def tfidf(texts, vocabulary):\n",
    "    document_counts = defaultdict(int)\n",
    "    for text in texts:\n",
    "        unique_tokens = set(text.split())\n",
    "        for token in unique_tokens:\n",
    "            document_counts[token] += 1\n",
    "\n",
    "    tfidf_vectors = []\n",
    "    for text in texts:\n",
    "        tokenized = text.split()\n",
    "        tfidf_vector = np.zeros(len(vocabulary))\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in tokenized:\n",
    "                tf = tokenized.count(word) / len(tokenized)\n",
    "                idf = np.log(len(texts) / (1 + document_counts[word]))\n",
    "                tfidf_vector[i] = tf * idf\n",
    "        tfidf_vectors.append(tfidf_vector)\n",
    "    return np.array(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 7775), (4457, 7775))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание словаря и применение методов BoW и TF-IDF\n",
    "vocabulary = create_vocabulary(X_train)\n",
    "bow_train = bow(X_train, vocabulary)\n",
    "tfidf_train = tfidf(X_train, vocabulary)\n",
    "\n",
    "# Просмотр размеров полученных векторов\n",
    "bow_train.shape, tfidf_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение с оригинальными методами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Train Shape: (4457, 7735)\n",
      "TF-IDF Train Shape: (4457, 7735)\n"
     ]
    }
   ],
   "source": [
    "data['v2'] = data['v2'].apply(clean)\n",
    "\n",
    "# Разбиение данных на тренировочные и тестовые наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['v2'], data['v1'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение CountVectorizer для BoW\n",
    "count_vectorizer = CountVectorizer()\n",
    "bow_train = count_vectorizer.fit_transform(X_train)\n",
    "bow_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Применение TfidfVectorizer для TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Получение размеров векторов\n",
    "print(\"BoW Train Shape:\", bow_train.shape)\n",
    "print(\"TF-IDF Train Shape:\", tfidf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Решить задачу с понижением размерности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      1.00      0.97       965\n",
      "        spam       0.98      0.62      0.76       150\n",
      "\n",
      "    accuracy                           0.95      1115\n",
      "   macro avg       0.96      0.81      0.86      1115\n",
      "weighted avg       0.95      0.95      0.94      1115\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(tfidf_train.toarray())\n",
    "X_test_pca = pca.transform(tfidf_test.toarray())\n",
    "\n",
    "# Обучение классификатора (я взял логистическую регрессию)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных и вывод результатов\n",
    "predictions = classifier.predict(X_test_pca)\n",
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "def format_classification_report(report):\n",
    "    formatted_report = \"\"\n",
    "    for line in report.split('\\n'):\n",
    "        formatted_report += line + \"\\n\"\n",
    "    return formatted_report\n",
    "\n",
    "# Форматированный отчет о классификации\n",
    "formatted_report = format_classification_report(report)\n",
    "print(formatted_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Решить задачу тематического моделирования с помощью LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тема 1: you to and my me the your day love good\n",
      "Тема 2: you to are call me how have what can do\n",
      "Тема 3: to free ur now call lor txt ok no or\n",
      "Тема 4: to you it the in and that be on will\n",
      "Тема 5: the is to your you in for lt gt and\n"
     ]
    }
   ],
   "source": [
    "# Выбор числа тем\n",
    "n_topics = 5\n",
    "\n",
    "# Векторизация текста\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_vectorized = vectorizer.fit_transform(data['v2'])\n",
    "\n",
    "# Создание и обучение модели LDA\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X_vectorized)\n",
    "\n",
    "# Получение тем и слов\n",
    "words = vectorizer.get_feature_names_out()\n",
    "topics = lda.components_\n",
    "\n",
    "# Вывод тем с их словами\n",
    "for topic_idx, topic in enumerate(topics):\n",
    "    top_words_indices = topic.argsort()[-10:][::-1]  # Индексы слов с наибольшим весом в теме\n",
    "    top_words = [words[i] for i in top_words_indices]\n",
    "    print(f\"Тема {topic_idx + 1}: {' '.join(top_words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
